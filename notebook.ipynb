{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 78,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
   "execution_count": 78,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "id": "782f64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "# from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
=======
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
    "from PIL import Image\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 79,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
   "execution_count": 79,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "id": "1759db33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
=======
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
       "      <td>How I feel today #legday #jelly #aching #gym</td>\n",
       "      <td>1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ArrivaTW absolute disgrace two carriages from...</td>\n",
       "      <td>10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is my Valentine's from 1 of my nephews. I...</td>\n",
       "      <td>100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betterfeelingfilms: RT via Instagram: First da...</td>\n",
       "      <td>1000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zoe's first love #Rattled @JohnnyHarper15</td>\n",
       "      <td>1001.jpg</td>\n",
<<<<<<< HEAD
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <th>40450</th>\n",
       "      <td>A man in a pink shirt climbs a rock face</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>A man is rock climbing high in the air .</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>A person in a red shirt climbing up a rock fac...</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>A rock climber in a red shirt .</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>A rock climber practices on a rock climbing wa...</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40455 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Caption                   image_id\n",
       "0      A child in a pink dress is climbing up a set o...  1000268201_693b08cb0e.jpg\n",
       "1                  A girl going into a wooden building .  1000268201_693b08cb0e.jpg\n",
       "2       A little girl climbing into a wooden playhouse .  1000268201_693b08cb0e.jpg\n",
       "3      A little girl climbing the stairs to her playh...  1000268201_693b08cb0e.jpg\n",
       "4      A little girl in a pink dress going into a woo...  1000268201_693b08cb0e.jpg\n",
       "...                                                  ...                        ...\n",
       "40450           A man in a pink shirt climbs a rock face   997722733_0cb5439472.jpg\n",
       "40451           A man is rock climbing high in the air .   997722733_0cb5439472.jpg\n",
       "40452  A person in a red shirt climbing up a rock fac...   997722733_0cb5439472.jpg\n",
       "40453                    A rock climber in a red shirt .   997722733_0cb5439472.jpg\n",
       "40454  A rock climber practices on a rock climbing wa...   997722733_0cb5439472.jpg\n",
       "\n",
       "[40455 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
=======
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
       "      <th>4864</th>\n",
       "      <td>OMG. Well done #Eskom! 'Man dies during #LoadS...</td>\n",
       "      <td>995.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865</th>\n",
       "      <td>Feelin' the love in here! #ValentinesDay #caring</td>\n",
       "      <td>996.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>#blue #eyes can't be #beaten</td>\n",
       "      <td>997.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>LA CHUCHA LOUUU TE CHUPO LOS OJOS..!</td>\n",
       "      <td>998.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>#colorsplash_bw #zealous Remedios #herbales y ...</td>\n",
       "      <td>999.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4869 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Caption  image_id\n",
       "0         How I feel today #legday #jelly #aching #gym      1.jpg\n",
       "1     @ArrivaTW absolute disgrace two carriages from...    10.jpg\n",
       "2     This is my Valentine's from 1 of my nephews. I...   100.jpg\n",
       "3     betterfeelingfilms: RT via Instagram: First da...  1000.jpg\n",
       "4            Zoe's first love #Rattled @JohnnyHarper15   1001.jpg\n",
       "...                                                 ...       ...\n",
       "4864  OMG. Well done #Eskom! 'Man dies during #LoadS...   995.jpg\n",
       "4865  Feelin' the love in here! #ValentinesDay #caring    996.jpg\n",
       "4866                      #blue #eyes can't be #beaten    997.jpg\n",
       "4867              LA CHUCHA LOUUU TE CHUPO LOS OJOS..!    998.jpg\n",
       "4868  #colorsplash_bw #zealous Remedios #herbales y ...   999.jpg\n",
       "\n",
       "[4869 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
<<<<<<< HEAD
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "labels = pd.read_csv(\"captions.txt\")[[\"Caption\", \"image_id\"]]\n",
=======
    "labels = pd.read_excel(\"Captions.xlsx\")[[\"Caption\", \"image_id\"]]\n",
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
    "labels = pd.read_excel(\"Captions.xlsx\")[[\"Caption\", \"image_id\"]]\n",
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
    "labels"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 80,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
   "execution_count": 80,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "id": "e2104ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
<<<<<<< HEAD
<<<<<<< HEAD
      "RangeIndex: 40455 entries, 0 to 40454\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Caption   40455 non-null  object\n",
      " 1   image_id  40455 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 632.2+ KB\n"
=======
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
      "RangeIndex: 4869 entries, 0 to 4868\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Caption   4869 non-null   object\n",
      " 1   image_id  4869 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 76.2+ KB\n"
<<<<<<< HEAD
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
     ]
    }
   ],
   "source": [
    "labels.info()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 81,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
   "execution_count": 81,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "id": "c3a70bf6",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
<<<<<<< HEAD
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │   <span style=\"color: #00af00; text-decoration-color: #00af00\">102,764,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc1 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │   \u001b[38;5;34m102,764,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc2 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,260,544</span> (512.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,260,544\u001b[0m (512.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,260,544</span> (512.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,260,544\u001b[0m (512.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
=======
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Feature Extraction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vgg = \u001b[43mVGG16\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m vgg = Model(inputs=vgg.inputs, outputs=vgg.layers[-\u001b[32m2\u001b[39m].output)\n\u001b[32m      4\u001b[39m vgg.summary()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\applications\\vgg16.py:211\u001b[39m, in \u001b[36mVGG16\u001b[39m\u001b[34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights == \u001b[33m\"\u001b[39m\u001b[33mimagenet\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m include_top:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m         weights_path = \u001b[43mfile_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvgg16_weights_tf_dim_ordering_tf_kernels.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[43mWEIGHTS_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_subdir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m64373286793e3c8b2b4e3219cbf3544b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    218\u001b[39m         weights_path = file_utils.get_file(\n\u001b[32m    219\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mvgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    220\u001b[39m             WEIGHTS_PATH_NO_TOP,\n\u001b[32m    221\u001b[39m             cache_subdir=\u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m             file_hash=\u001b[33m\"\u001b[39m\u001b[33m6d6bbae143d832006294945121d1f1fc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    223\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:269\u001b[39m, in \u001b[36mget_file\u001b[39m\u001b[34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;66;03m# Verify integrity if a hash was provided.\u001b[39;00m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mvalidate_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhash_algorithm\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    272\u001b[39m         io_utils.print_msg(\n\u001b[32m    273\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mA local file was found, but it seems to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    274\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mincomplete or outdated because the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhash_algorithm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    275\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfile hash does not match the original value of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    276\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m so we will re-download the data.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    277\u001b[39m         )\n\u001b[32m    278\u001b[39m         download = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:406\u001b[39m, in \u001b[36mvalidate_file\u001b[39m\u001b[34m(fpath, file_hash, algorithm, chunk_size)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Validates a file against a sha256 or md5 hash.\u001b[39;00m\n\u001b[32m    392\u001b[39m \n\u001b[32m    393\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    402\u001b[39m \u001b[33;03m    Boolean, whether the file is valid.\u001b[39;00m\n\u001b[32m    403\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    404\u001b[39m hasher = resolve_hasher(algorithm, file_hash)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[43mhash_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m) == \u001b[38;5;28mstr\u001b[39m(file_hash):\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:385\u001b[39m, in \u001b[36mhash_file\u001b[39m\u001b[34m(fpath, algorithm, chunk_size)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fpath, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fpath_file:\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: fpath_file.read(chunk_size), \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         hasher.update(chunk)\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hasher.hexdigest()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
<<<<<<< HEAD
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
    }
   ],
   "source": [
    "# Feature Extraction\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "# vgg = VGG16()\n",
    "# vgg = Model(inputs=vgg.inputs, outputs=vgg.layers[-2].output)\n",
    "# vgg.summary()\n",
    "\n",
    "resnet = ResNet50()\n",
    "resnet = Model(inputs=ResNet50().inputs, outputs=ResNet50().layers[-2].output)\n",
    "resnet.summary()"
=======
    "vgg = VGG16()\n",
    "vgg = Model(inputs=vgg.inputs, outputs=vgg.layers[-2].output)\n",
    "vgg.summary()"
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
    "vgg = VGG16()\n",
    "vgg = Model(inputs=vgg.inputs, outputs=vgg.layers[-2].output)\n",
    "vgg.summary()"
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "BASE_DIR = \"./Images/\"\n",
    "images = os.listdir(BASE_DIR)\n",
    "\n",
    "for img in images:\n",
    "    image_path = os.path.join(BASE_DIR, img)\n",
    "    image = Image.open(image_path).resize((224, 224))\n",
    "\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    feature = resnet.predict(image, verbose=0)\n",
=======
    "    feature = vgg.predict(image, verbose=0)\n",
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
    "    feature = vgg.predict(image, verbose=0)\n",
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
    "\n",
    "    image_idx = str(img).split(\".\")[0]\n",
    "    features[image_idx] = feature\n",
    "\n",
    "pickle.dump(features, open(\"image_features.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 82,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
   "execution_count": 82,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "id": "0bc6b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Twitter captions\n",
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "    def remove_username(self, tweet):\n",
    "        return re.sub(r\"@(\\w+)\", \"\", tweet)\n",
    "    \n",
    "    def remove_punctuations(self, tweet):\n",
    "        puncs = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"-\", \"_\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\", \"/\", \"\\\\\", \"|\", \"@\", \"$\", \"%\", \"^\", \"&\", \"*\", \"+\", \"=\", \"~\", \"`\", \"RT\"]\n",
    "        for punc in puncs:\n",
    "            tweet = tweet.replace(punc, \"\")\n",
    "        return tweet\n",
    "\n",
    "    def remove_stopwords(self, tweet):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "        filtered_tweets = [t for t in tweet.split(\" \") if t.lower() not in stop_words]\n",
    "        filtered_tweets = \" \".join(filtered_tweets).strip()\n",
    "        return filtered_tweets\n",
    "    \n",
    "    def lemmatize(self, tweet):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized = [lemmatizer.lemmatize(t) for t in tweet.split(\" \")]\n",
    "        lemmatized = \" \".join(lemmatized)\n",
    "        return lemmatized\n",
    "    \n",
    "    def stem_words(self, tweet):\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed = [stemmer.stem(t) for t in tweet.split(\" \")]\n",
    "        stemmed = \" \".join(stemmed)\n",
    "        return stemmed"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 83,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
   "execution_count": 83,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "id": "654d85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor()\n",
    "labels[\"Caption\"] = labels[\"Caption\"].fillna(\"\").astype(str)\n",
    "labels[\"Caption\"] = labels[\"Caption\"].apply(preprocessor.remove_username)\n",
    "labels[\"Caption\"] = labels[\"Caption\"].apply(preprocessor.remove_punctuations)\n",
    "labels[\"Caption\"] = labels[\"Caption\"].apply(preprocessor.remove_stopwords)\n",
    "labels[\"Caption\"] = labels[\"Caption\"].apply(preprocessor.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 84,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
   "execution_count": 84,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "id": "b1059058",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"./\", \"image_features.pkl\"), \"rb\") as f:\n",
    "    image_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 85,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
   "execution_count": 85,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "id": "5ba59e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[\"Caption\"] = labels[\"Caption\"].apply(lambda x: \"<start> \" + x + \" <end>\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 31,
   "id": "1debb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH =  max(len(caption.split()) for caption in labels[\"Caption\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
=======
   "execution_count": 86,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
   "execution_count": 86,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "id": "1499ef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
<<<<<<< HEAD
      "Vocab size:  7651\n"
=======
      "Vocab size:  15173\n"
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
      "Vocab size:  15173\n"
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(labels[\"Caption\"].values)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 87,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
   "execution_count": 87,
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "id": "c083f9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>&lt;start&gt; child pink dress climbing set stair en...</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; girl going wooden building &lt;end&gt;</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; little girl climbing wooden playhouse ...</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; little girl climbing stair playhouse &lt;...</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; little girl pink dress going wooden ca...</td>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
=======
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
       "      <td>&lt;start&gt; feel today #legday #jelly #aching #gym...</td>\n",
       "      <td>1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; absolute disgrace two carriage Bangor ...</td>\n",
       "      <td>10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; Valentine's 1 nephew elated sometimes ...</td>\n",
       "      <td>100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; betterfeelingfilms  via Instagram Firs...</td>\n",
       "      <td>1000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; Zoe's first love #Rattled &lt;end&gt;</td>\n",
       "      <td>1001.jpg</td>\n",
<<<<<<< HEAD
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <th>40450</th>\n",
       "      <td>&lt;start&gt; man pink shirt climb rock face &lt;end&gt;</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>&lt;start&gt; man rock climbing high air &lt;end&gt;</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>&lt;start&gt; person red shirt climbing rock face co...</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>&lt;start&gt; rock climber red shirt &lt;end&gt;</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>&lt;start&gt; rock climber practice rock climbing wa...</td>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40455 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Caption                   image_id\n",
       "0      <start> child pink dress climbing set stair en...  1000268201_693b08cb0e.jpg\n",
       "1               <start> girl going wooden building <end>  1000268201_693b08cb0e.jpg\n",
       "2      <start> little girl climbing wooden playhouse ...  1000268201_693b08cb0e.jpg\n",
       "3      <start> little girl climbing stair playhouse <...  1000268201_693b08cb0e.jpg\n",
       "4      <start> little girl pink dress going wooden ca...  1000268201_693b08cb0e.jpg\n",
       "...                                                  ...                        ...\n",
       "40450       <start> man pink shirt climb rock face <end>   997722733_0cb5439472.jpg\n",
       "40451           <start> man rock climbing high air <end>   997722733_0cb5439472.jpg\n",
       "40452  <start> person red shirt climbing rock face co...   997722733_0cb5439472.jpg\n",
       "40453               <start> rock climber red shirt <end>   997722733_0cb5439472.jpg\n",
       "40454  <start> rock climber practice rock climbing wa...   997722733_0cb5439472.jpg\n",
       "\n",
       "[40455 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
=======
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
       "      <th>4864</th>\n",
       "      <td>&lt;start&gt; OMG Well done #Eskom 'Man dy #LoadShed...</td>\n",
       "      <td>995.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865</th>\n",
       "      <td>&lt;start&gt; Feelin' love #ValentinesDay #caring &lt;end&gt;</td>\n",
       "      <td>996.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>&lt;start&gt; #blue #eyes can't #beaten &lt;end&gt;</td>\n",
       "      <td>997.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>&lt;start&gt; LA CHUCHA LOUUU TE CHUPO LOS OJOS &lt;end&gt;</td>\n",
       "      <td>998.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>&lt;start&gt; #colorsplashbw #zealous Remedios #herb...</td>\n",
       "      <td>999.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4869 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Caption  image_id\n",
       "0     <start> feel today #legday #jelly #aching #gym...     1.jpg\n",
       "1     <start> absolute disgrace two carriage Bangor ...    10.jpg\n",
       "2     <start> Valentine's 1 nephew elated sometimes ...   100.jpg\n",
       "3     <start> betterfeelingfilms  via Instagram Firs...  1000.jpg\n",
       "4               <start> Zoe's first love #Rattled <end>  1001.jpg\n",
       "...                                                 ...       ...\n",
       "4864  <start> OMG Well done #Eskom 'Man dy #LoadShed...   995.jpg\n",
       "4865  <start> Feelin' love #ValentinesDay #caring <end>   996.jpg\n",
       "4866            <start> #blue #eyes can't #beaten <end>   997.jpg\n",
       "4867    <start> LA CHUCHA LOUUU TE CHUPO LOS OJOS <end>   998.jpg\n",
       "4868  <start> #colorsplashbw #zealous Remedios #herb...   999.jpg\n",
       "\n",
       "[4869 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
<<<<<<< HEAD
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60fdebc",
   "metadata": {},
<<<<<<< HEAD
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def generate_data(keys, labels, max_length, tokenizer, vocab_size, batch_size=32):\n",
=======
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image features: (44972, 4096), Input sequence: (44972, 235), Output sequence: (44972, 15173)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "def generate_data(features, labels, max_length, tokenizer, vocab_size):\n",
<<<<<<< HEAD
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
    "    \"\"\"\n",
    "    Organize the data into image features, input sequence features and the label (output sequence).\n",
    "\n",
    "    features - image features\n",
    "    labels - caption dataframe\n",
    "    max)_length - maximum length of the caption\n",
    "    tokenizer - tokenizer object\n",
    "    vocab_size - total # of classes the model can predict\n",
    "    \"\"\"\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    img_features, i_sequence, o_sequence = list(), list(), list()\n",
    "    counter = 0\n",
    "    while 1:\n",
    "        for key in keys:\n",
    "            counter +=1\n",
    "            image_feature = image_features[key][0] #(4096,)\n",
    "\n",
    "            labels_per_image = labels[labels[\"image_id\"] == f\"{key}.jpg\"][\"Caption\"].values\n",
    "            #labels_per_image = labels[labels[\"image_id\"] == f\"{key}.jpg\"][\"Caption\"].values[0]\n",
    "            \n",
    "            # print(labels_per_image, key)\n",
    "            for label in labels_per_image:\n",
    "\n",
    "                label_split = tokenizer.texts_to_sequences([label])[0]\n",
    "                for i in range(1,len(label_split)):\n",
    "                    prev, next = label_split[:i], label_split[i]\n",
    "\n",
    "                    in_seq = pad_sequences([prev], maxlen=max_length, padding='post')[0].astype('int32')\n",
    "                    # out_seq = to_categorical([next], \tnum_classes=vocab_size)[0].astype('float16')\n",
    "                    \n",
    "                    img_features.append(image_feature)\n",
    "                    i_sequence.append(in_seq)\n",
    "                    o_sequence.append(next)\n",
    "\n",
    "            if counter == batch_size:\n",
    "                yield (np.array(img_features, dtype='float32'), np.array(i_sequence, dtype='int32')), np.array(o_sequence, dtype='int32')\n",
    "                img_features, i_sequence, o_sequence = list(), list(), list()\n",
    "                counter = 0\n",
    "                    \n",
    "# data = generate_data(image_features, labels, max_length=MAX_LENGTH, tokenizer=tokenizer, vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fd435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding(glove_file):\n",
    "    features = {}\n",
    "    with open(glove_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            word = line.split()[0]\n",
    "            vec = np.array(line.split()[1:], dtype=\"float32\")\n",
    "\n",
    "            features[word] = vec\n",
    "\n",
    "        return features\n",
    "word_to_vec = pretrained_embedding(\"glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8a0b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(vocab_size):\n",
    "    embedding_matrix = np.zeros((vocab_size, 50))\n",
    "\n",
    "    for word, i in word_to_vec.items():\n",
    "        if word in tokenizer.word_index:\n",
    "            idx = tokenizer.word_index[word]\n",
    "            embedding_matrix[idx] = word_to_vec[word]\n",
    "        \n",
    "    embedding_layer = Embedding(vocab_size, 50, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([embedding_matrix])\n",
    "    return embedding_layer\n",
    "\n",
    "pretrained_embedding = pretrained_embedding_layer(len(tokenizer.word_index)+1)"
=======
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
    "    image_features, i_sequence, o_sequence = [],[],[]\n",
    "\n",
    "    for key in features.keys():\n",
    "        image_feature = features[key][0] #(4096,)\n",
    "\n",
    "        label = labels[labels[\"image_id\"] == f\"{key}.jpg\"][\"Caption\"].values[0]\n",
    "        # print(label)\n",
    "        label_split = tokenizer.texts_to_sequences([label])[0]\n",
    "        for i in range(1,len(label_split)):\n",
    "            prev, next = label_split[:i], label_split[i]\n",
    "\n",
    "            in_seq = pad_sequences([prev], maxlen=max_length, padding='post')[0]\n",
    "            out_seq = to_categorical([next], \tnum_classes=vocab_size)[0]\n",
    "\n",
    "            image_features.append(image_feature)\n",
    "            i_sequence.append(in_seq)\n",
    "            o_sequence.append(out_seq)\n",
    "    return np.array(image_features), np.array(i_sequence), np.array(o_sequence)\n",
    "\n",
    "img_features, i_sequence, o_sequence = generate_data(image_features, labels, max_length=235, tokenizer=tokenizer, vocab_size=vocab_size)\n",
    "print(f\"Image features: {img_features.shape}, Input sequence: {i_sequence.shape}, Output sequence: {o_sequence.shape}\")"
<<<<<<< HEAD
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc4ed5",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
<<<<<<< HEAD
    "# Model\n",
    "\n",
    "def caption_generator_model(vocab_size):\n",
    "    image_input = Input(shape=(4096,))\n",
    "    second_last_layer = Dropout(0.5)(image_input) # trainable 2nd last layer\n",
    "    last_layer = Dense(256, activation='relu')(second_last_layer) # trainable last layer\n",
    "\n",
    "    text_input = Input(shape=(MAX_LENGTH,))\n",
    "\n",
    "    # embedding = Embedding(input_dim=vocab_size, output_dim=256)(text_input)\n",
    "    embedding = pretrained_embedding(text_input) \n",
    "\n",
    "    t = Dropout(0.5)(embedding)\n",
    "    t = LSTM(256)(t) \n",
    "\n",
    "    concat = add([last_layer, t])\n",
    "\n",
    "    res = Dense(256, activation='relu')(concat)\n",
    "    res = Dense(vocab_size, activation='softmax')(res)\n",
    "\n",
    "    model = Model(inputs=[image_input, text_input], outputs=res)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = caption_generator_model(vocab_size=7651)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56bafb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">382,550</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,832</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">314,368</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7651</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,966,307</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │    \u001b[38;5;34m382,550\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │  \u001b[38;5;34m1,048,832\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m314,368\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7651\u001b[0m)      │  \u001b[38;5;34m1,966,307\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777,849</span> (14.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,777,849\u001b[0m (14.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,395,299</span> (12.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,395,299\u001b[0m (12.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">382,550</span> (1.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m382,550\u001b[0m (1.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0d1aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 631ms/step - accuracy: 0.1493 - loss: 5.8384\n",
      "Epoch 2/10\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 638ms/step - accuracy: 0.2234 - loss: 4.5395\n",
      "Epoch 3/10\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 517ms/step - accuracy: 0.2421 - loss: 4.2186\n",
      "Epoch 4/10\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 469ms/step - accuracy: 0.2507 - loss: 4.0027\n",
      "Epoch 5/10\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 480ms/step - accuracy: 0.2592 - loss: 3.8273\n",
      "Epoch 6/10\n",
      "\u001b[1m 12/252\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 478ms/step - accuracy: 0.2629 - loss: 3.7206"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m generator = \u001b[38;5;28;01mlambda\u001b[39;00m: generate_data(\u001b[38;5;28mlist\u001b[39m(image_features.keys()), labels, max_length=MAX_LENGTH, tokenizer=tokenizer, vocab_size=vocab_size)\n\u001b[32m     14\u001b[39m dataset = tf.data.Dataset.from_generator(generator, output_signature=output_signature)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "steps = len(image_features) // 32\n",
    "# creating a directory named models to save our models\n",
    "import tensorflow as tf\n",
    "\n",
    "output_signature = (\n",
    "    (\n",
    "        tf.TensorSpec(shape=(None, 4096), dtype='float32'),  # image features\n",
    "        tf.TensorSpec(shape=(None, MAX_LENGTH), dtype='int32')  # input sequence\n",
    "    ),\n",
    "    tf.TensorSpec(shape=(None,), dtype='int32')  # output sequence\n",
    ")\n",
    "\n",
    "generator = lambda: generate_data(list(image_features.keys()), labels, max_length=MAX_LENGTH, tokenizer=tokenizer, vocab_size=vocab_size)\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=output_signature)\n",
    "model.fit(dataset, steps_per_epoch= steps, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d7f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> man\n",
      "<start> man white\n",
      "<start> man white shirt\n",
      "<start> man white shirt shirt\n",
      "<start> man white shirt shirt shirt\n",
      "<start> man white shirt shirt shirt shirt\n",
      "<start> man white shirt shirt shirt shirt shirt\n",
      "<start> man white shirt shirt shirt shirt shirt shirt\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "TEST_PATH = \"Test/\"\n",
    "def write_caption(image_name, reference):\n",
    "    caption = \"<start>\"\n",
    "    \n",
    "    image_path = os.path.join(TEST_PATH, image_name)\n",
    "    image = Image.open(image_path).resize((224, 224))\n",
    "    \n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)   \n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    feature = vgg.predict(image, verbose=0)\n",
    "\n",
    "    while True:\n",
    "        tokenized = tokenizer.texts_to_sequences([caption])[0]\n",
    "        in_seq = pad_sequences([tokenized], maxlen=MAX_LENGTH, padding='post')[0].astype('int32')\n",
    "        in_seq = np.expand_dims(in_seq, axis=0)\n",
    "        pred = model.predict([feature, in_seq], verbose=0)\n",
    "  \n",
    "        next_word = np.argmax(pred[0])\n",
    "\n",
    "        caption += \" \" + tokenizer.index_word[next_word]\n",
    "        if tokenizer.index_word[next_word] == \"end\":\n",
    "            break\n",
    "\n",
    "        print(caption)\n",
    "\n",
    "    # Calculate BLEU score\n",
    "    reference = [ref.split() for ref in reference]\n",
    "    caption = caption.split()\n",
    "    score = sentence_bleu(reference, caption, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    print(\"BLEU score: \", score)\n",
    "\n",
    "references = [\n",
    "    ['man with a white shirt and a hat'],\n",
    "    ['man holding a hat'],\n",
    "    ['man with a brown bowler hat']\n",
    "]\n",
    "\n",
    "write_caption(\"download.jpg\", references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c48dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [\n",
    "    ['man with a white shirt and a hat'],\n",
    "    ['man holding a hat'],\n",
    "    ['man with a brown bowler hat']\n",
    "]\n",
    "\n",
    "write_caption(\"download.jpg\", references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8618f6ec",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- validate the above runs without issue\n",
    "- create another notebook to do it for Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ac827",
   "metadata": {},
   "source": []
=======
    "# Model"
   ]
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
=======
    "# Model"
   ]
>>>>>>> 49dacfd23cb673b87e8c49880774a71eed7ab894
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

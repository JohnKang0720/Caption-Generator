{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "782f64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
    "from PIL import Image\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1759db33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How I feel today #legday #jelly #aching #gym</td>\n",
       "      <td>1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ArrivaTW absolute disgrace two carriages from...</td>\n",
       "      <td>10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is my Valentine's from 1 of my nephews. I...</td>\n",
       "      <td>100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betterfeelingfilms: RT via Instagram: First da...</td>\n",
       "      <td>1000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zoe's first love #Rattled @JohnnyHarper15</td>\n",
       "      <td>1001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>OMG. Well done #Eskom! 'Man dies during #LoadS...</td>\n",
       "      <td>995.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865</th>\n",
       "      <td>Feelin' the love in here! #ValentinesDay #caring</td>\n",
       "      <td>996.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>#blue #eyes can't be #beaten</td>\n",
       "      <td>997.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>LA CHUCHA LOUUU TE CHUPO LOS OJOS..!</td>\n",
       "      <td>998.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>#colorsplash_bw #zealous Remedios #herbales y ...</td>\n",
       "      <td>999.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4869 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Caption  image_id\n",
       "0         How I feel today #legday #jelly #aching #gym      1.jpg\n",
       "1     @ArrivaTW absolute disgrace two carriages from...    10.jpg\n",
       "2     This is my Valentine's from 1 of my nephews. I...   100.jpg\n",
       "3     betterfeelingfilms: RT via Instagram: First da...  1000.jpg\n",
       "4            Zoe's first love #Rattled @JohnnyHarper15   1001.jpg\n",
       "...                                                 ...       ...\n",
       "4864  OMG. Well done #Eskom! 'Man dies during #LoadS...   995.jpg\n",
       "4865  Feelin' the love in here! #ValentinesDay #caring    996.jpg\n",
       "4866                      #blue #eyes can't be #beaten    997.jpg\n",
       "4867              LA CHUCHA LOUUU TE CHUPO LOS OJOS..!    998.jpg\n",
       "4868  #colorsplash_bw #zealous Remedios #herbales y ...   999.jpg\n",
       "\n",
       "[4869 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_excel(\"Captions.xlsx\")[[\"Caption\", \"image_id\"]]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e2104ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4869 entries, 0 to 4868\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Caption   4869 non-null   object\n",
      " 1   image_id  4869 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 76.2+ KB\n"
     ]
    }
   ],
   "source": [
    "labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3a70bf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Feature Extraction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vgg = \u001b[43mVGG16\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m vgg = Model(inputs=vgg.inputs, outputs=vgg.layers[-\u001b[32m2\u001b[39m].output)\n\u001b[32m      4\u001b[39m vgg.summary()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\applications\\vgg16.py:211\u001b[39m, in \u001b[36mVGG16\u001b[39m\u001b[34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights == \u001b[33m\"\u001b[39m\u001b[33mimagenet\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m include_top:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m         weights_path = \u001b[43mfile_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvgg16_weights_tf_dim_ordering_tf_kernels.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[43mWEIGHTS_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_subdir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m64373286793e3c8b2b4e3219cbf3544b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    218\u001b[39m         weights_path = file_utils.get_file(\n\u001b[32m    219\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mvgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    220\u001b[39m             WEIGHTS_PATH_NO_TOP,\n\u001b[32m    221\u001b[39m             cache_subdir=\u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m             file_hash=\u001b[33m\"\u001b[39m\u001b[33m6d6bbae143d832006294945121d1f1fc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    223\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:269\u001b[39m, in \u001b[36mget_file\u001b[39m\u001b[34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;66;03m# Verify integrity if a hash was provided.\u001b[39;00m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mvalidate_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhash_algorithm\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    272\u001b[39m         io_utils.print_msg(\n\u001b[32m    273\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mA local file was found, but it seems to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    274\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mincomplete or outdated because the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhash_algorithm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    275\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfile hash does not match the original value of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    276\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m so we will re-download the data.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    277\u001b[39m         )\n\u001b[32m    278\u001b[39m         download = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:406\u001b[39m, in \u001b[36mvalidate_file\u001b[39m\u001b[34m(fpath, file_hash, algorithm, chunk_size)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Validates a file against a sha256 or md5 hash.\u001b[39;00m\n\u001b[32m    392\u001b[39m \n\u001b[32m    393\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    402\u001b[39m \u001b[33;03m    Boolean, whether the file is valid.\u001b[39;00m\n\u001b[32m    403\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    404\u001b[39m hasher = resolve_hasher(algorithm, file_hash)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[43mhash_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m) == \u001b[38;5;28mstr\u001b[39m(file_hash):\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kangj\\OneDrive\\Desktop\\Twitter Caption Generator\\venv\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:385\u001b[39m, in \u001b[36mhash_file\u001b[39m\u001b[34m(fpath, algorithm, chunk_size)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fpath, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fpath_file:\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: fpath_file.read(chunk_size), \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         hasher.update(chunk)\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hasher.hexdigest()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "vgg = VGG16()\n",
    "vgg = Model(inputs=vgg.inputs, outputs=vgg.layers[-2].output)\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "BASE_DIR = \"./Images/\"\n",
    "images = os.listdir(BASE_DIR)\n",
    "\n",
    "for img in images:\n",
    "    image_path = os.path.join(BASE_DIR, img)\n",
    "    image = Image.open(image_path).resize((224, 224))\n",
    "\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    feature = vgg.predict(image, verbose=0)\n",
    "\n",
    "    image_idx = str(img).split(\".\")[0]\n",
    "    features[image_idx] = feature\n",
    "\n",
    "pickle.dump(features, open(\"image_features.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bc6b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Twitter captions\n",
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "    def remove_username(self, tweet):\n",
    "        return re.sub(r\"@(\\w+)\", \"\", tweet)\n",
    "    \n",
    "    def remove_punctuations(self, tweet):\n",
    "        puncs = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"-\", \"_\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\", \"/\", \"\\\\\", \"|\", \"@\", \"$\", \"%\", \"^\", \"&\", \"*\", \"+\", \"=\", \"~\", \"`\", \"RT\"]\n",
    "        for punc in puncs:\n",
    "            tweet = tweet.replace(punc, \"\")\n",
    "        return tweet\n",
    "\n",
    "    def remove_stopwords(self, tweet):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "        filtered_tweets = [t for t in tweet.split(\" \") if t.lower() not in stop_words]\n",
    "        filtered_tweets = \" \".join(filtered_tweets).strip()\n",
    "        return filtered_tweets\n",
    "    \n",
    "    def lemmatize(self, tweet):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized = [lemmatizer.lemmatize(t) for t in tweet.split(\" \")]\n",
    "        lemmatized = \" \".join(lemmatized)\n",
    "        return lemmatized\n",
    "    \n",
    "    def stem_words(self, tweet):\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed = [stemmer.stem(t) for t in tweet.split(\" \")]\n",
    "        stemmed = \" \".join(stemmed)\n",
    "        return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "654d85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor()\n",
    "labels[\"Caption\"] = labels[\"Caption\"].fillna(\"\").astype(str)\n",
    "labels[\"Caption\"] = labels[\"Caption\"].apply(preprocessor.remove_username)\n",
    "labels[\"Caption\"] = labels[\"Caption\"].apply(preprocessor.remove_punctuations)\n",
    "labels[\"Caption\"] = labels[\"Caption\"].apply(preprocessor.remove_stopwords)\n",
    "labels[\"Caption\"] = labels[\"Caption\"].apply(preprocessor.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1059058",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"./\", \"image_features.pkl\"), \"rb\") as f:\n",
    "    image_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ba59e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[\"Caption\"] = labels[\"Caption\"].apply(lambda x: \"<start> \" + x + \" <end>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1499ef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  15173\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(labels[\"Caption\"].values)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c083f9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; feel today #legday #jelly #aching #gym...</td>\n",
       "      <td>1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; absolute disgrace two carriage Bangor ...</td>\n",
       "      <td>10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; Valentine's 1 nephew elated sometimes ...</td>\n",
       "      <td>100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; betterfeelingfilms  via Instagram Firs...</td>\n",
       "      <td>1000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; Zoe's first love #Rattled &lt;end&gt;</td>\n",
       "      <td>1001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>&lt;start&gt; OMG Well done #Eskom 'Man dy #LoadShed...</td>\n",
       "      <td>995.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865</th>\n",
       "      <td>&lt;start&gt; Feelin' love #ValentinesDay #caring &lt;end&gt;</td>\n",
       "      <td>996.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>&lt;start&gt; #blue #eyes can't #beaten &lt;end&gt;</td>\n",
       "      <td>997.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>&lt;start&gt; LA CHUCHA LOUUU TE CHUPO LOS OJOS &lt;end&gt;</td>\n",
       "      <td>998.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>&lt;start&gt; #colorsplashbw #zealous Remedios #herb...</td>\n",
       "      <td>999.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4869 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Caption  image_id\n",
       "0     <start> feel today #legday #jelly #aching #gym...     1.jpg\n",
       "1     <start> absolute disgrace two carriage Bangor ...    10.jpg\n",
       "2     <start> Valentine's 1 nephew elated sometimes ...   100.jpg\n",
       "3     <start> betterfeelingfilms  via Instagram Firs...  1000.jpg\n",
       "4               <start> Zoe's first love #Rattled <end>  1001.jpg\n",
       "...                                                 ...       ...\n",
       "4864  <start> OMG Well done #Eskom 'Man dy #LoadShed...   995.jpg\n",
       "4865  <start> Feelin' love #ValentinesDay #caring <end>   996.jpg\n",
       "4866            <start> #blue #eyes can't #beaten <end>   997.jpg\n",
       "4867    <start> LA CHUCHA LOUUU TE CHUPO LOS OJOS <end>   998.jpg\n",
       "4868  <start> #colorsplashbw #zealous Remedios #herb...   999.jpg\n",
       "\n",
       "[4869 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60fdebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image features: (44972, 4096), Input sequence: (44972, 235), Output sequence: (44972, 15173)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "def generate_data(features, labels, max_length, tokenizer, vocab_size):\n",
    "    \"\"\"\n",
    "    Organize the data into image features, input sequence features and the label (output sequence).\n",
    "\n",
    "    features - image features\n",
    "    labels - caption dataframe\n",
    "    max)_length - maximum length of the caption\n",
    "    tokenizer - tokenizer object\n",
    "    vocab_size - total # of classes the model can predict\n",
    "    \"\"\"\n",
    "    image_features, i_sequence, o_sequence = [],[],[]\n",
    "\n",
    "    for key in features.keys():\n",
    "        image_feature = features[key][0] #(4096,)\n",
    "\n",
    "        label = labels[labels[\"image_id\"] == f\"{key}.jpg\"][\"Caption\"].values[0]\n",
    "        # print(label)\n",
    "        label_split = tokenizer.texts_to_sequences([label])[0]\n",
    "        for i in range(1,len(label_split)):\n",
    "            prev, next = label_split[:i], label_split[i]\n",
    "\n",
    "            in_seq = pad_sequences([prev], maxlen=max_length, padding='post')[0]\n",
    "            out_seq = to_categorical([next], \tnum_classes=vocab_size)[0]\n",
    "\n",
    "            image_features.append(image_feature)\n",
    "            i_sequence.append(in_seq)\n",
    "            o_sequence.append(out_seq)\n",
    "    return np.array(image_features), np.array(i_sequence), np.array(o_sequence)\n",
    "\n",
    "img_features, i_sequence, o_sequence = generate_data(image_features, labels, max_length=235, tokenizer=tokenizer, vocab_size=vocab_size)\n",
    "print(f\"Image features: {img_features.shape}, Input sequence: {i_sequence.shape}, Output sequence: {o_sequence.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc4ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
